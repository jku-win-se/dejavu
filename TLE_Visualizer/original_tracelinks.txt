F1:AllowAllAuthenticator:An authenticator handles the authentication challenge/response cycles of a single connection.
F1:AllowAllAuthority:An authenticator handles the authentication challenge/response cycles of a single connection.
F1:AuthenticatedUser:An authenticator handles the authentication challenge/response cycles of a single connection.
F1:IAuthenticator:An authenticator handles the authentication challenge/response cycles of a single connection.
F1:IAuthority:An authenticator handles the authentication challenge/response cycles of a single connection.
F1:Permission:An authenticator handles the authentication challenge/response cycles of a single connection.
F1:SimpleAuthenticator:An authenticator handles the authentication challenge/response cycles of a single connection.
F1:SimpleAuthority:An authenticator handles the authentication challenge/response cycles of a single connection.
F2:Icache:Cassandra supports row mutation.
F3:IRowCacheProvider:The RandomPartitioner is the default partitioning strategy for a Cassandra cluster, and in almost all cases is the right choice. The RandomPartitioner uses consistent hashing to determine which node stores which row. 
F3:ConcurrentLinkedHashCache:The RandomPartitioner is the default partitioning strategy for a Cassandra cluster, and in almost all cases is the right choice. The RandomPartitioner uses consistent hashing to determine which node stores which row. 
F3:ConcurrentLinkedHashCacheProvider:The RandomPartitioner is the default partitioning strategy for a Cassandra cluster, and in almost all cases is the right choice. The RandomPartitioner uses consistent hashing to determine which node stores which row. 
F3:FreeableMemory:The RandomPartitioner is the default partitioning strategy for a Cassandra cluster, and in almost all cases is the right choice. The RandomPartitioner uses consistent hashing to determine which node stores which row. 
F3:InstrumentingCache:The RandomPartitioner is the default partitioning strategy for a Cassandra cluster, and in almost all cases is the right choice. The RandomPartitioner uses consistent hashing to determine which node stores which row. 
F3:InstrumentingCacheMBean:The RandomPartitioner is the default partitioning strategy for a Cassandra cluster, and in almost all cases is the right choice. The RandomPartitioner uses consistent hashing to determine which node stores which row. 
F3:SerializingCache:The RandomPartitioner is the default partitioning strategy for a Cassandra cluster, and in almost all cases is the right choice. The RandomPartitioner uses consistent hashing to determine which node stores which row. 
F3:SerializingCacheProvider:The RandomPartitioner is the default partitioning strategy for a Cassandra cluster, and in almost all cases is the right choice. The RandomPartitioner uses consistent hashing to determine which node stores which row. 
F4:AutoSavingRowCache:The RackInferringSnitch determines the location of nodes by rack and data center, which are assumed to correspond to the 3rd and 2nd octet of the node's IP address, respectively. Use this snitch as an example of writing a custom Snitch class.
F4:AutoSavingKeyCache:The RackInferringSnitch determines the location of nodes by rack and data center, which are assumed to correspond to the 3rd and 2nd octet of the node's IP address, respectively. Use this snitch as an example of writing a custom Snitch class.
F4:AutoSavingCache:The RackInferringSnitch determines the location of nodes by rack and data center, which are assumed to correspond to the 3rd and 2nd octet of the node's IP address, respectively. Use this snitch as an example of writing a custom Snitch class.
F5:CliClient:Streaming is a component which handles data (part of SSTable file) exchange among nodes in the cluster. When you bootstrap a new node, it gets data from existing nodes using streaming.
F5:CliCommandHelp:Streaming is a component which handles data (part of SSTable file) exchange among nodes in the cluster. When you bootstrap a new node, it gets data from existing nodes using streaming.
F5:CliCompiler:Streaming is a component which handles data (part of SSTable file) exchange among nodes in the cluster. When you bootstrap a new node, it gets data from existing nodes using streaming.
F5:CliCompleter:Streaming is a component which handles data (part of SSTable file) exchange among nodes in the cluster. When you bootstrap a new node, it gets data from existing nodes using streaming.
F5:CliMain:Streaming is a component which handles data (part of SSTable file) exchange among nodes in the cluster. When you bootstrap a new node, it gets data from existing nodes using streaming.
F5:CliOptions:Streaming is a component which handles data (part of SSTable file) exchange among nodes in the cluster. When you bootstrap a new node, it gets data from existing nodes using streaming.
F5:CliSessionState:Streaming is a component which handles data (part of SSTable file) exchange among nodes in the cluster. When you bootstrap a new node, it gets data from existing nodes using streaming.
F5:CliUserHelp:Streaming is a component which handles data (part of SSTable file) exchange among nodes in the cluster. When you bootstrap a new node, it gets data from existing nodes using streaming.
F5:CliUtils:Streaming is a component which handles data (part of SSTable file) exchange among nodes in the cluster. When you bootstrap a new node, it gets data from existing nodes using streaming.
F6:AIOExecutorService:Streaming is a component which handles data (part of SSTable file) exchange among nodes in the cluster. When you bootstrap a new node, it gets data from existing nodes using streaming.
F6:Context:Streaming is a component which handles data (part of SSTable file) exchange among nodes in the cluster. When you bootstrap a new node, it gets data from existing nodes using streaming.
F6:CreationTimeAwareFuture:Streaming is a component which handles data (part of SSTable file) exchange among nodes in the cluster. When you bootstrap a new node, it gets data from existing nodes using streaming.
F6:DebuggableScheduledThreadPoolExecutor:Streaming is a component which handles data (part of SSTable file) exchange among nodes in the cluster. When you bootstrap a new node, it gets data from existing nodes using streaming.
F6:DebuggableThreadPoolExecutor:Streaming is a component which handles data (part of SSTable file) exchange among nodes in the cluster. When you bootstrap a new node, it gets data from existing nodes using streaming.
F6:IExecutorMBean:Streaming is a component which handles data (part of SSTable file) exchange among nodes in the cluster. When you bootstrap a new node, it gets data from existing nodes using streaming.
F6:NamedThreadFactory:Streaming is a component which handles data (part of SSTable file) exchange among nodes in the cluster. When you bootstrap a new node, it gets data from existing nodes using streaming.
F6:Stage:Streaming is a component which handles data (part of SSTable file) exchange among nodes in the cluster. When you bootstrap a new node, it gets data from existing nodes using streaming.
F6:StageManager:Streaming is a component which handles data (part of SSTable file) exchange among nodes in the cluster. When you bootstrap a new node, it gets data from existing nodes using streaming.
F7:JMXConfigurableThreadPoolExecutor:Streaming is a component which handles data (part of SSTable file) exchange among nodes in the cluster. When you bootstrap a new node, it gets data from existing nodes using streaming.
F7:JMXConfigurableThreadPoolExecutorMBean:Streaming is a component which handles data (part of SSTable file) exchange among nodes in the cluster. When you bootstrap a new node, it gets data from existing nodes using streaming.
F7:JMXEnabledThreadPoolExecutor:Streaming is a component which handles data (part of SSTable file) exchange among nodes in the cluster. When you bootstrap a new node, it gets data from existing nodes using streaming.
F7:JMXEnabledThreadPoolExecutorMBean:Streaming is a component which handles data (part of SSTable file) exchange among nodes in the cluster. When you bootstrap a new node, it gets data from existing nodes using streaming.
F8:CFMetaData:Streaming is a component which handles data (part of SSTable file) exchange among nodes in the cluster. When you bootstrap a new node, it gets data from existing nodes using streaming.
F8:ColumnDefinition:Streaming is a component which handles data (part of SSTable file) exchange among nodes in the cluster. When you bootstrap a new node, it gets data from existing nodes using streaming.
F9:EncryptionOptions:Streaming is a component which handles data (part of SSTable file) exchange among nodes in the cluster. When you bootstrap a new node, it gets data from existing nodes using streaming.
F10:KSMetaData:An authenticator handles the authentication challenge/response cycles of a single connection.
F11:ReplicationStrategy:An authenticator handles the authentication challenge/response cycles of a single connection.
F12:AlterTableStatement:Cassandra Query Language (CQL) 
F12:Attributes:Cassandra Query Language (CQL) 
F13:BatchStatement:A BATCH statement combines multiple data modification (DML) CQL statements into a single logical operation. BATCH supports setting a client-supplied, global consistency level and timestamp that is used for each of the operations included in the batch.
F12:CQLStatement:Cassandra Query Language (CQL) 
F8:CreateColumnFamilyStatement:Streaming is a component which handles data (part of SSTable file) exchange among nodes in the cluster. When you bootstrap a new node, it gets data from existing nodes using streaming.
F12:CreateIndexStatement:Cassandra Query Language (CQL) 
F10:CreateKeyspaceStatement:An authenticator handles the authentication challenge/response cycles of a single connection.
F12:DeleteStatement:Cassandra Query Language (CQL) 
F12:DropIndexStatement:Cassandra Query Language (CQL) 
F12:Operation:Cassandra Query Language (CQL) 
F12:QueryProcessor:Cassandra Query Language (CQL) 
F12:Relation:Cassandra Query Language (CQL) 
F12:SelectExpression:Cassandra Query Language (CQL) 
F12:SelectStatement:Cassandra Query Language (CQL) 
F12:StatementType:Cassandra Query Language (CQL) 
F12:UpdateStatement:Cassandra Query Language (CQL) 
F12:WhereClause:Cassandra Query Language (CQL) 
F14:AbstractJdbcType:Developers can access CQL commands in a variety of ways such as JDBC-based client programs.
F14:AbstractJdbcUUID:Developers can access CQL commands in a variety of ways such as JDBC-based client programs.
F14:JdbcAscii:Developers can access CQL commands in a variety of ways such as JDBC-based client programs.
F14:JdbcBoolean:Developers can access CQL commands in a variety of ways such as JDBC-based client programs.
F14:JdbcBytes:Developers can access CQL commands in a variety of ways such as JDBC-based client programs.
F14:JdbcCounterColumn:Developers can access CQL commands in a variety of ways such as JDBC-based client programs.
F14:JdbcDate:Developers can access CQL commands in a variety of ways such as JDBC-based client programs.
F14:JdbcDecimal:Developers can access CQL commands in a variety of ways such as JDBC-based client programs.
F14:JdbcDouble:Developers can access CQL commands in a variety of ways such as JDBC-based client programs.
F14:JdbcFloat:Developers can access CQL commands in a variety of ways such as JDBC-based client programs.
F14:JdbcInt32:Developers can access CQL commands in a variety of ways such as JDBC-based client programs.
F14:JdbcInteger:Developers can access CQL commands in a variety of ways such as JDBC-based client programs.
F14:JdbcLexicalUUID:Developers can access CQL commands in a variety of ways such as JDBC-based client programs.
F14:JdbcLong:Developers can access CQL commands in a variety of ways such as JDBC-based client programs.
F14:JdbcTimeUUID:Developers can access CQL commands in a variety of ways such as JDBC-based client programs.
F14:JdbcUTF8:Developers can access CQL commands in a variety of ways such as JDBC-based client programs.
F14:JdbcUUID:Developers can access CQL commands in a variety of ways such as JDBC-based client programs.
F14:TypesMap:Developers can access CQL commands in a variety of ways such as JDBC-based client programs.
F8:AbstractColumnContainer:Streaming is a component which handles data (part of SSTable file) exchange among nodes in the cluster. When you bootstrap a new node, it gets data from existing nodes using streaming.
F8:ArrayBackedSortedColumns:Streaming is a component which handles data (part of SSTable file) exchange among nodes in the cluster. When you bootstrap a new node, it gets data from existing nodes using streaming.
F8:CollationController:Streaming is a component which handles data (part of SSTable file) exchange among nodes in the cluster. When you bootstrap a new node, it gets data from existing nodes using streaming.
F8:Column:Streaming is a component which handles data (part of SSTable file) exchange among nodes in the cluster. When you bootstrap a new node, it gets data from existing nodes using streaming.
F8:ColumnFamily:Streaming is a component which handles data (part of SSTable file) exchange among nodes in the cluster. When you bootstrap a new node, it gets data from existing nodes using streaming.
F8:ColumnFamilyNotDefinedException:Streaming is a component which handles data (part of SSTable file) exchange among nodes in the cluster. When you bootstrap a new node, it gets data from existing nodes using streaming.
F8:ColumnFamilySerializer:Streaming is a component which handles data (part of SSTable file) exchange among nodes in the cluster. When you bootstrap a new node, it gets data from existing nodes using streaming.
F8:ColumnFamilyStore:Streaming is a component which handles data (part of SSTable file) exchange among nodes in the cluster. When you bootstrap a new node, it gets data from existing nodes using streaming.
F8:ColumnFamilyStoreMBean:Streaming is a component which handles data (part of SSTable file) exchange among nodes in the cluster. When you bootstrap a new node, it gets data from existing nodes using streaming.
F8:ColumnFamilyType:Streaming is a component which handles data (part of SSTable file) exchange among nodes in the cluster. When you bootstrap a new node, it gets data from existing nodes using streaming.
F8:ColumnIndexer:Streaming is a component which handles data (part of SSTable file) exchange among nodes in the cluster. When you bootstrap a new node, it gets data from existing nodes using streaming.
F8:ColumnSerializer:Streaming is a component which handles data (part of SSTable file) exchange among nodes in the cluster. When you bootstrap a new node, it gets data from existing nodes using streaming.
F15:CounterColumn:"A counter is a special kind of column used to store a number that incrementally counts the occurrences of a particular event or process. For example, you might use a counter column to count the number of times a page is viewed. Counter columns are different from regular columns in that once a counter is defined, the client application then updates
F15:CounterMutation:"A counter is a special kind of column used to store a number that incrementally counts the occurrences of a particular event or process. For example, you might use a counter column to count the number of times a page is viewed. Counter columns are different from regular columns in that once a counter is defined, the client application then updates
F15:CounterMutationVerbHandler:"A counter is a special kind of column used to store a number that incrementally counts the occurrences of a particular event or process. For example, you might use a counter column to count the number of times a page is viewed. Counter columns are different from regular columns in that once a counter is defined, the client application then updates
F15:CounterUpdateColumn:"A counter is a special kind of column used to store a number that incrementally counts the occurrences of a particular event or process. For example, you might use a counter column to count the number of times a page is viewed. Counter columns are different from regular columns in that once a counter is defined, the client application then updates
F16:ExpiringColumn:"A column can also have an optional expiration date called TTL (time to live). Whenever a column is inserted, the client
F18:HintedHandOffManager:Hinted handoff is an optional feature of Cassandra that reduces the time to restore a failed node to consistency once the failed node returns to the cluster. It can also be used for absolute write availability for applications that cannot tolerate a failed write, but can tolerate inconsistent reads
F18:HintedHandOffManagerMBean:Hinted handoff is an optional feature of Cassandra that reduces the time to restore a failed node to consistency once the failed node returns to the cluster. It can also be used for absolute write availability for applications that cannot tolerate a failed write, but can tolerate inconsistent reads
F8:IColumn:Streaming is a component which handles data (part of SSTable file) exchange among nodes in the cluster. When you bootstrap a new node, it gets data from existing nodes using streaming.
F8:IColumnContainer:Streaming is a component which handles data (part of SSTable file) exchange among nodes in the cluster. When you bootstrap a new node, it gets data from existing nodes using streaming.
F19:IMutation:Cassandra supports row mutation.
F20:Memtable:Cassandra writes are first written to the CommitLog, and then to a per-ColumnFamily structure called a Memtable. A Memtable is basically a write-back cache of data rows that can be looked up by key -- that is, unlike a write-through cache, writes are batched up in the Memtable until it is full, when it is flushed.
F21:MeteredFlusher:"When thresholds are reached, Cassandra periodically flushes in-memory data structures (memtables) to SSTable
F22:RangeSliceCommand:Most applications can be designed with a data model that supports ordered queries as slices over a set of columns rather than range scans over a set of rows.
F22:RangeSliceReply:Most applications can be designed with a data model that supports ordered queries as slices over a set of columns rather than range scans over a set of rows.
F19:RowMutation:Cassandra supports row mutation.
F19:RowMutationVerbHandler:Cassandra supports row mutation.
F22:SliceByNamesReadCommand:Most applications can be designed with a data model that supports ordered queries as slices over a set of columns rather than range scans over a set of rows.
F22:SliceFromReadCommand:Most applications can be designed with a data model that supports ordered queries as slices over a set of columns rather than range scans over a set of rows.
F17:SuperColumn:A Cassandra column family can contain either regular columns or super columns, which adds another level of nesting to the regular column family structure. Super columns are comprised of a (super) column name and an ordered map of sub-columns. A super column can specify a comparator on both the super column name as well as on the sub-column names.
F24:TruncateResponse:A TRUNCATE statement results in the immediate, irreversible removal of all data in the named column family.
F24:TruncateVerbHandler:A TRUNCATE statement results in the immediate, irreversible removal of all data in the named column family.
F24:Truncation:A TRUNCATE statement results in the immediate, irreversible removal of all data in the named column family.
F8:IColumnIterator:Streaming is a component which handles data (part of SSTable file) exchange among nodes in the cluster. When you bootstrap a new node, it gets data from existing nodes using streaming.
F8:ICountableColumnIterator:Streaming is a component which handles data (part of SSTable file) exchange among nodes in the cluster. When you bootstrap a new node, it gets data from existing nodes using streaming.
F27:IdentityQueryFilter:Adds WHERE arguments to the queryset, returning a new queryset and Returns a QuerySet filtered on the keyword arguments.
F22:IndexedSliceReader:Most applications can be designed with a data model that supports ordered queries as slices over a set of columns rather than range scans over a set of rows.
F8:SimpleAbstractColumnIterator:Streaming is a component which handles data (part of SSTable file) exchange among nodes in the cluster. When you bootstrap a new node, it gets data from existing nodes using streaming.
F22:SimpleSliceReader:Most applications can be designed with a data model that supports ordered queries as slices over a set of columns rather than range scans over a set of rows.
F23:SSTableNamesIterator:When a Memtable is full, Cassandra writes to disk as an SSTable. SSTable - sorted string table, key/value storage sorted by keys. SSTable is on-disk data structure and is always immutable.
F23:SSTableSliceIterator:When a Memtable is full, Cassandra writes to disk as an SSTable. SSTable - sorted string table, key/value storage sorted by keys. SSTable is on-disk data structure and is always immutable.
F25:AbstractCommutativeType:Marshal defines Cassandra operations for persistence of complex Haskell data objects with custom-selected but implicitly performed serialization.
F25:AbstractCompositeType:Marshal defines Cassandra operations for persistence of complex Haskell data objects with custom-selected but implicitly performed serialization.
F25:AbstractType:Marshal defines Cassandra operations for persistence of complex Haskell data objects with custom-selected but implicitly performed serialization.
F25:AsciiType:Marshal defines Cassandra operations for persistence of complex Haskell data objects with custom-selected but implicitly performed serialization.
F25:BooleanType:Marshal defines Cassandra operations for persistence of complex Haskell data objects with custom-selected but implicitly performed serialization.
F25:BytesType:Marshal defines Cassandra operations for persistence of complex Haskell data objects with custom-selected but implicitly performed serialization.
F25:CompositeType:Marshal defines Cassandra operations for persistence of complex Haskell data objects with custom-selected but implicitly performed serialization.
F25:CounterColumnType:Marshal defines Cassandra operations for persistence of complex Haskell data objects with custom-selected but implicitly performed serialization.
F25:DateType:Marshal defines Cassandra operations for persistence of complex Haskell data objects with custom-selected but implicitly performed serialization.
F25:DecimalType:Marshal defines Cassandra operations for persistence of complex Haskell data objects with custom-selected but implicitly performed serialization.
F25:DoubleType:Marshal defines Cassandra operations for persistence of complex Haskell data objects with custom-selected but implicitly performed serialization.
F25:DynamicCompositeType:Marshal defines Cassandra operations for persistence of complex Haskell data objects with custom-selected but implicitly performed serialization.
F25:FloatType:Marshal defines Cassandra operations for persistence of complex Haskell data objects with custom-selected but implicitly performed serialization.
F25:Int32Type:Marshal defines Cassandra operations for persistence of complex Haskell data objects with custom-selected but implicitly performed serialization.
F25:IntegerType:Marshal defines Cassandra operations for persistence of complex Haskell data objects with custom-selected but implicitly performed serialization.
F25:LexicalUUIDType:Marshal defines Cassandra operations for persistence of complex Haskell data objects with custom-selected but implicitly performed serialization.
F25:LocalByPartionerType:Marshal defines Cassandra operations for persistence of complex Haskell data objects with custom-selected but implicitly performed serialization.
F25:LongType:Marshal defines Cassandra operations for persistence of complex Haskell data objects with custom-selected but implicitly performed serialization.
F25:MarshalException:Marshal defines Cassandra operations for persistence of complex Haskell data objects with custom-selected but implicitly performed serialization.
F25:ReversedType:Marshal defines Cassandra operations for persistence of complex Haskell data objects with custom-selected but implicitly performed serialization.
F25:TimeUUIDType:Marshal defines Cassandra operations for persistence of complex Haskell data objects with custom-selected but implicitly performed serialization.
F25:TypeParser:Marshal defines Cassandra operations for persistence of complex Haskell data objects with custom-selected but implicitly performed serialization.
F25:UTF8Type:Marshal defines Cassandra operations for persistence of complex Haskell data objects with custom-selected but implicitly performed serialization.
F25:UUIDType:Marshal defines Cassandra operations for persistence of complex Haskell data objects with custom-selected but implicitly performed serialization.
F26:AbstractCompactedRow:In the background, Cassandra periodically merges SSTables together into larger SSTables using a process called compaction. Compaction merges row fragments together, removes expired tombstones (deleted columns), and rebuilds primary and secondary indexes.
F26:AbstractCompactionIterable:In the background, Cassandra periodically merges SSTables together into larger SSTables using a process called compaction. Compaction merges row fragments together, removes expired tombstones (deleted columns), and rebuilds primary and secondary indexes.
F26:AbstractCompactionStrategy:In the background, Cassandra periodically merges SSTables together into larger SSTables using a process called compaction. Compaction merges row fragments together, removes expired tombstones (deleted columns), and rebuilds primary and secondary indexes.
F26:AbstractCompactionTask:In the background, Cassandra periodically merges SSTables together into larger SSTables using a process called compaction. Compaction merges row fragments together, removes expired tombstones (deleted columns), and rebuilds primary and secondary indexes.
F26:CompactionController:In the background, Cassandra periodically merges SSTables together into larger SSTables using a process called compaction. Compaction merges row fragments together, removes expired tombstones (deleted columns), and rebuilds primary and secondary indexes.
F26:CompactionInfo:In the background, Cassandra periodically merges SSTables together into larger SSTables using a process called compaction. Compaction merges row fragments together, removes expired tombstones (deleted columns), and rebuilds primary and secondary indexes.
F26:CompactionIterable:In the background, Cassandra periodically merges SSTables together into larger SSTables using a process called compaction. Compaction merges row fragments together, removes expired tombstones (deleted columns), and rebuilds primary and secondary indexes.
F26:CompactionManager:In the background, Cassandra periodically merges SSTables together into larger SSTables using a process called compaction. Compaction merges row fragments together, removes expired tombstones (deleted columns), and rebuilds primary and secondary indexes.
F26:CompactionManagerMBean:In the background, Cassandra periodically merges SSTables together into larger SSTables using a process called compaction. Compaction merges row fragments together, removes expired tombstones (deleted columns), and rebuilds primary and secondary indexes.
F26:CompactionTask:In the background, Cassandra periodically merges SSTables together into larger SSTables using a process called compaction. Compaction merges row fragments together, removes expired tombstones (deleted columns), and rebuilds primary and secondary indexes.
F26:LazilyCompactedRow:In the background, Cassandra periodically merges SSTables together into larger SSTables using a process called compaction. Compaction merges row fragments together, removes expired tombstones (deleted columns), and rebuilds primary and secondary indexes.
F26:LeveledCompactionStrategy:In the background, Cassandra periodically merges SSTables together into larger SSTables using a process called compaction. Compaction merges row fragments together, removes expired tombstones (deleted columns), and rebuilds primary and secondary indexes.
F26:LeveledCompactionTask:In the background, Cassandra periodically merges SSTables together into larger SSTables using a process called compaction. Compaction merges row fragments together, removes expired tombstones (deleted columns), and rebuilds primary and secondary indexes.
F26:LeveledManifest:In the background, Cassandra periodically merges SSTables together into larger SSTables using a process called compaction. Compaction merges row fragments together, removes expired tombstones (deleted columns), and rebuilds primary and secondary indexes.
F26:OperationType:In the background, Cassandra periodically merges SSTables together into larger SSTables using a process called compaction. Compaction merges row fragments together, removes expired tombstones (deleted columns), and rebuilds primary and secondary indexes.
F26:ParallelCompactionIterable:In the background, Cassandra periodically merges SSTables together into larger SSTables using a process called compaction. Compaction merges row fragments together, removes expired tombstones (deleted columns), and rebuilds primary and secondary indexes.
F26:PrecompactedRow:In the background, Cassandra periodically merges SSTables together into larger SSTables using a process called compaction. Compaction merges row fragments together, removes expired tombstones (deleted columns), and rebuilds primary and secondary indexes.
F26:SizeTieredCompactionStrategy:In the background, Cassandra periodically merges SSTables together into larger SSTables using a process called compaction. Compaction merges row fragments together, removes expired tombstones (deleted columns), and rebuilds primary and secondary indexes.
F27:AbstractColumnIterator:Adds WHERE arguments to the queryset, returning a new queryset and Returns a QuerySet filtered on the keyword arguments.
F27:IFilter:Adds WHERE arguments to the queryset, returning a new queryset and Returns a QuerySet filtered on the keyword arguments.
F27:NamesQueryFilter:Adds WHERE arguments to the queryset, returning a new queryset and Returns a QuerySet filtered on the keyword arguments.
F27:QueryFilter:Adds WHERE arguments to the queryset, returning a new queryset and Returns a QuerySet filtered on the keyword arguments.
F27:QueryPath:Adds WHERE arguments to the queryset, returning a new queryset and Returns a QuerySet filtered on the keyword arguments.
F27:SliceQueryFilter:Adds WHERE arguments to the queryset, returning a new queryset and Returns a QuerySet filtered on the keyword arguments.
F28:AbstractBounds:Unlike almost every other configuration choice in Cassandra, the partitioner cannot be changed without reloading all of your data. Therefore, it is important to choose and configure the correct partitioner before initializing your cluster. 
F28:AbstractByteOrderedPartitioner:Unlike almost every other configuration choice in Cassandra, the partitioner cannot be changed without reloading all of your data. Therefore, it is important to choose and configure the correct partitioner before initializing your cluster. 
F28:BigIntegerToken:Unlike almost every other configuration choice in Cassandra, the partitioner cannot be changed without reloading all of your data. Therefore, it is important to choose and configure the correct partitioner before initializing your cluster. 
F28:BootStrapper:Unlike almost every other configuration choice in Cassandra, the partitioner cannot be changed without reloading all of your data. Therefore, it is important to choose and configure the correct partitioner before initializing your cluster. 
F28:Bounds:Unlike almost every other configuration choice in Cassandra, the partitioner cannot be changed without reloading all of your data. Therefore, it is important to choose and configure the correct partitioner before initializing your cluster. 
F31:ByteOrderedPartitioner:Cassandra provides the ByteOrderedPartitioner forordered partitioning. This partitioner orders rows lexically by key bytes. An order-preserving partitioner that operates on partition key bytes lexicographically. 
F28:BytesToken:Unlike almost every other configuration choice in Cassandra, the partitioner cannot be changed without reloading all of your data. Therefore, it is important to choose and configure the correct partitioner before initializing your cluster. 
F30:CollatingOrderPreservingPartitioner:Assumes keys are UTF8 strings. Not recommended both because of this limitation and because globally ordering all your partitions generates hot spots: some partitions close together will get more activity than others, and the node hosting those will be overloaded relative to others. 
F28:IPartitioner:Unlike almost every other configuration choice in Cassandra, the partitioner cannot be changed without reloading all of your data. Therefore, it is important to choose and configure the correct partitioner before initializing your cluster. 
F28:LocalPartitioner:Unlike almost every other configuration choice in Cassandra, the partitioner cannot be changed without reloading all of your data. Therefore, it is important to choose and configure the correct partitioner before initializing your cluster. 
F28:LocalToken:Unlike almost every other configuration choice in Cassandra, the partitioner cannot be changed without reloading all of your data. Therefore, it is important to choose and configure the correct partitioner before initializing your cluster. 
F30:OrderPreservingPartitioner:Assumes keys are UTF8 strings. Not recommended both because of this limitation and because globally ordering all your partitions generates hot spots: some partitions close together will get more activity than others, and the node hosting those will be overloaded relative to others. 
F29:RandomPartitioner:The RandomPartitioner is the default partitioning strategy for a Cassandra cluster, and in almost all cases is the right choice. The RandomPartitioner uses consistent hashing to determine which node stores which row. 
F28:Range:Unlike almost every other configuration choice in Cassandra, the partitioner cannot be changed without reloading all of your data. Therefore, it is important to choose and configure the correct partitioner before initializing your cluster. 
F28:StringToken:Unlike almost every other configuration choice in Cassandra, the partitioner cannot be changed without reloading all of your data. Therefore, it is important to choose and configure the correct partitioner before initializing your cluster. 
F28:Token:Unlike almost every other configuration choice in Cassandra, the partitioner cannot be changed without reloading all of your data. Therefore, it is important to choose and configure the correct partitioner before initializing your cluster. 
F32:ApplicationState:Failure detection is a method for locally determining, from gossip state, if another node in the system is up or down. Failure detection information is also used by Cassandra to avoid routing client requests to unreachable nodes whenever possible.
F32:EndpointState:Failure detection is a method for locally determining, from gossip state, if another node in the system is up or down. Failure detection information is also used by Cassandra to avoid routing client requests to unreachable nodes whenever possible.
F32:FailureDetector:Failure detection is a method for locally determining, from gossip state, if another node in the system is up or down. Failure detection information is also used by Cassandra to avoid routing client requests to unreachable nodes whenever possible.
F32:FailureDetectorMBean:Failure detection is a method for locally determining, from gossip state, if another node in the system is up or down. Failure detection information is also used by Cassandra to avoid routing client requests to unreachable nodes whenever possible.
F33:GossipDigest:The gossip process tracks heartbeats from other nodes both directly (nodes gossiping directly to it) and indirectly (nodes heard about secondhand, thirdhand, and so on)Gossip is a peer-to-peer communication protocol in which nodes periodically exchange state information about themselves and about other nodes they know about. The gossip process runs every second and exchanges state messages with up to three other nodes in the cluster. The nodes exchange information about themselves and about the other nodes that they have gossiped about, so all nodes quickly learn about all other nodes in the cluster. A gossip message has a version associated with it, so that during a gossip exchange, older information is overwritten with the most current state for a particular node. Cassandra uses a protocol called gossip to discover location and state information about the other nodes participating in a Cassandra cluster. 
F33:GossipDigestAck2Message:The gossip process tracks heartbeats from other nodes both directly (nodes gossiping directly to it) and indirectly (nodes heard about secondhand, thirdhand, and so on)Gossip is a peer-to-peer communication protocol in which nodes periodically exchange state information about themselves and about other nodes they know about. The gossip process runs every second and exchanges state messages with up to three other nodes in the cluster. The nodes exchange information about themselves and about the other nodes that they have gossiped about, so all nodes quickly learn about all other nodes in the cluster. A gossip message has a version associated with it, so that during a gossip exchange, older information is overwritten with the most current state for a particular node. Cassandra uses a protocol called gossip to discover location and state information about the other nodes participating in a Cassandra cluster. 
F33:GossipDigestAck2VerbHandler:The gossip process tracks heartbeats from other nodes both directly (nodes gossiping directly to it) and indirectly (nodes heard about secondhand, thirdhand, and so on)Gossip is a peer-to-peer communication protocol in which nodes periodically exchange state information about themselves and about other nodes they know about. The gossip process runs every second and exchanges state messages with up to three other nodes in the cluster. The nodes exchange information about themselves and about the other nodes that they have gossiped about, so all nodes quickly learn about all other nodes in the cluster. A gossip message has a version associated with it, so that during a gossip exchange, older information is overwritten with the most current state for a particular node. Cassandra uses a protocol called gossip to discover location and state information about the other nodes participating in a Cassandra cluster. 
F33:GossipDigestAckMessage:The gossip process tracks heartbeats from other nodes both directly (nodes gossiping directly to it) and indirectly (nodes heard about secondhand, thirdhand, and so on)Gossip is a peer-to-peer communication protocol in which nodes periodically exchange state information about themselves and about other nodes they know about. The gossip process runs every second and exchanges state messages with up to three other nodes in the cluster. The nodes exchange information about themselves and about the other nodes that they have gossiped about, so all nodes quickly learn about all other nodes in the cluster. A gossip message has a version associated with it, so that during a gossip exchange, older information is overwritten with the most current state for a particular node. Cassandra uses a protocol called gossip to discover location and state information about the other nodes participating in a Cassandra cluster. 
F33:GossipDigestAckVerbHandler:The gossip process tracks heartbeats from other nodes both directly (nodes gossiping directly to it) and indirectly (nodes heard about secondhand, thirdhand, and so on)Gossip is a peer-to-peer communication protocol in which nodes periodically exchange state information about themselves and about other nodes they know about. The gossip process runs every second and exchanges state messages with up to three other nodes in the cluster. The nodes exchange information about themselves and about the other nodes that they have gossiped about, so all nodes quickly learn about all other nodes in the cluster. A gossip message has a version associated with it, so that during a gossip exchange, older information is overwritten with the most current state for a particular node. Cassandra uses a protocol called gossip to discover location and state information about the other nodes participating in a Cassandra cluster. 
F33:GossipDigestSynMessage:The gossip process tracks heartbeats from other nodes both directly (nodes gossiping directly to it) and indirectly (nodes heard about secondhand, thirdhand, and so on)Gossip is a peer-to-peer communication protocol in which nodes periodically exchange state information about themselves and about other nodes they know about. The gossip process runs every second and exchanges state messages with up to three other nodes in the cluster. The nodes exchange information about themselves and about the other nodes that they have gossiped about, so all nodes quickly learn about all other nodes in the cluster. A gossip message has a version associated with it, so that during a gossip exchange, older information is overwritten with the most current state for a particular node. Cassandra uses a protocol called gossip to discover location and state information about the other nodes participating in a Cassandra cluster. 
F33:GossipDigestSynVerbHandler:The gossip process tracks heartbeats from other nodes both directly (nodes gossiping directly to it) and indirectly (nodes heard about secondhand, thirdhand, and so on)Gossip is a peer-to-peer communication protocol in which nodes periodically exchange state information about themselves and about other nodes they know about. The gossip process runs every second and exchanges state messages with up to three other nodes in the cluster. The nodes exchange information about themselves and about the other nodes that they have gossiped about, so all nodes quickly learn about all other nodes in the cluster. A gossip message has a version associated with it, so that during a gossip exchange, older information is overwritten with the most current state for a particular node. Cassandra uses a protocol called gossip to discover location and state information about the other nodes participating in a Cassandra cluster. 
F33:Gossiper:The gossip process tracks heartbeats from other nodes both directly (nodes gossiping directly to it) and indirectly (nodes heard about secondhand, thirdhand, and so on)Gossip is a peer-to-peer communication protocol in which nodes periodically exchange state information about themselves and about other nodes they know about. The gossip process runs every second and exchanges state messages with up to three other nodes in the cluster. The nodes exchange information about themselves and about the other nodes that they have gossiped about, so all nodes quickly learn about all other nodes in the cluster. A gossip message has a version associated with it, so that during a gossip exchange, older information is overwritten with the most current state for a particular node. Cassandra uses a protocol called gossip to discover location and state information about the other nodes participating in a Cassandra cluster. 
F33:GossiperMBean:The gossip process tracks heartbeats from other nodes both directly (nodes gossiping directly to it) and indirectly (nodes heard about secondhand, thirdhand, and so on)Gossip is a peer-to-peer communication protocol in which nodes periodically exchange state information about themselves and about other nodes they know about. The gossip process runs every second and exchanges state messages with up to three other nodes in the cluster. The nodes exchange information about themselves and about the other nodes that they have gossiped about, so all nodes quickly learn about all other nodes in the cluster. A gossip message has a version associated with it, so that during a gossip exchange, older information is overwritten with the most current state for a particular node. Cassandra uses a protocol called gossip to discover location and state information about the other nodes participating in a Cassandra cluster. 
F32:HeartBeatState:Failure detection is a method for locally determining, from gossip state, if another node in the system is up or down. Failure detection information is also used by Cassandra to avoid routing client requests to unreachable nodes whenever possible.
F32:IEndpointStateChangeSubscriber:Failure detection is a method for locally determining, from gossip state, if another node in the system is up or down. Failure detection information is also used by Cassandra to avoid routing client requests to unreachable nodes whenever possible.
F32:IFailureDetectionEventListener:Failure detection is a method for locally determining, from gossip state, if another node in the system is up or down. Failure detection information is also used by Cassandra to avoid routing client requests to unreachable nodes whenever possible.
F32:IFailureDetector:Failure detection is a method for locally determining, from gossip state, if another node in the system is up or down. Failure detection information is also used by Cassandra to avoid routing client requests to unreachable nodes whenever possible.
F32:IFailureNotification:Failure detection is a method for locally determining, from gossip state, if another node in the system is up or down. Failure detection information is also used by Cassandra to avoid routing client requests to unreachable nodes whenever possible.
F32:PureRandom:Failure detection is a method for locally determining, from gossip state, if another node in the system is up or down. Failure detection information is also used by Cassandra to avoid routing client requests to unreachable nodes whenever possible.
F32:VersionedValue:Failure detection is a method for locally determining, from gossip state, if another node in the system is up or down. Failure detection information is also used by Cassandra to avoid routing client requests to unreachable nodes whenever possible.
F32:VersionGenerator:Failure detection is a method for locally determining, from gossip state, if another node in the system is up or down. Failure detection information is also used by Cassandra to avoid routing client requests to unreachable nodes whenever possible.
F34:ColumnFamilyInputFormat:allows you to read data stored in Cassandra from a Hadoop MapReduce job, and its companion class and  to write the results back into Cassandra. 
F34:ColumnFamilyOutputFormat:allows you to read data stored in Cassandra from a Hadoop MapReduce job, and its companion class and  to write the results back into Cassandra. 
F34:ColumnFamilyRecordReader:allows you to read data stored in Cassandra from a Hadoop MapReduce job, and its companion class and  to write the results back into Cassandra. 
F34:ColumnFamilyRecordWriter:allows you to read data stored in Cassandra from a Hadoop MapReduce job, and its companion class and  to write the results back into Cassandra. 
F34:ColumnFamilySplit:allows you to read data stored in Cassandra from a Hadoop MapReduce job, and its companion class and  to write the results back into Cassandra. 
F35:CompressedRandomAccessReader:Cassandra 1.0 introduces support for data compression on a per-ColumnFamily basis, one of the most-requested features since the project started. Compression maximizes the storage capacity of your Cassandra nodes by reducing the volume of data on disk.
F35:CompressedSequentialWriter:Cassandra 1.0 introduces support for data compression on a per-ColumnFamily basis, one of the most-requested features since the project started. Compression maximizes the storage capacity of your Cassandra nodes by reducing the volume of data on disk.
F35:CompressionMetadata:Cassandra 1.0 introduces support for data compression on a per-ColumnFamily basis, one of the most-requested features since the project started. Compression maximizes the storage capacity of your Cassandra nodes by reducing the volume of data on disk.
F35:CompressionParameters:Cassandra 1.0 introduces support for data compression on a per-ColumnFamily basis, one of the most-requested features since the project started. Compression maximizes the storage capacity of your Cassandra nodes by reducing the volume of data on disk.
F35:CorruptedBlockException:Cassandra 1.0 introduces support for data compression on a per-ColumnFamily basis, one of the most-requested features since the project started. Compression maximizes the storage capacity of your Cassandra nodes by reducing the volume of data on disk.
F35:DeflateCompressor:Cassandra 1.0 introduces support for data compression on a per-ColumnFamily basis, one of the most-requested features since the project started. Compression maximizes the storage capacity of your Cassandra nodes by reducing the volume of data on disk.
F35:ICompressor:Cassandra 1.0 introduces support for data compression on a per-ColumnFamily basis, one of the most-requested features since the project started. Compression maximizes the storage capacity of your Cassandra nodes by reducing the volume of data on disk.
F35:SnappyCompressor:Cassandra 1.0 introduces support for data compression on a per-ColumnFamily basis, one of the most-requested features since the project started. Compression maximizes the storage capacity of your Cassandra nodes by reducing the volume of data on disk.
F23:AbstractSSTableSimpleWriter:When a Memtable is full, Cassandra writes to disk as an SSTable. SSTable - sorted string table, key/value storage sorted by keys. SSTable is on-disk data structure and is always immutable.
F23:BloomFilterTracker:When a Memtable is full, Cassandra writes to disk as an SSTable. SSTable - sorted string table, key/value storage sorted by keys. SSTable is on-disk data structure and is always immutable.
F23:Component:When a Memtable is full, Cassandra writes to disk as an SSTable. SSTable - sorted string table, key/value storage sorted by keys. SSTable is on-disk data structure and is always immutable.
F23:Descriptor:When a Memtable is full, Cassandra writes to disk as an SSTable. SSTable - sorted string table, key/value storage sorted by keys. SSTable is on-disk data structure and is always immutable.
F23:IndexHelper:When a Memtable is full, Cassandra writes to disk as an SSTable. SSTable - sorted string table, key/value storage sorted by keys. SSTable is on-disk data structure and is always immutable.
F23:IndexSummary:When a Memtable is full, Cassandra writes to disk as an SSTable. SSTable - sorted string table, key/value storage sorted by keys. SSTable is on-disk data structure and is always immutable.
F23:KeyIterator:When a Memtable is full, Cassandra writes to disk as an SSTable. SSTable - sorted string table, key/value storage sorted by keys. SSTable is on-disk data structure and is always immutable.
F23:ReducingKeyIterator:When a Memtable is full, Cassandra writes to disk as an SSTable. SSTable - sorted string table, key/value storage sorted by keys. SSTable is on-disk data structure and is always immutable.
F23:SSTable:When a Memtable is full, Cassandra writes to disk as an SSTable. SSTable - sorted string table, key/value storage sorted by keys. SSTable is on-disk data structure and is always immutable.
F23:SSTableBoundedScanner:When a Memtable is full, Cassandra writes to disk as an SSTable. SSTable - sorted string table, key/value storage sorted by keys. SSTable is on-disk data structure and is always immutable.
F23:SSTableDeletingTask:When a Memtable is full, Cassandra writes to disk as an SSTable. SSTable - sorted string table, key/value storage sorted by keys. SSTable is on-disk data structure and is always immutable.
F23:SSTableIdentityIterator:When a Memtable is full, Cassandra writes to disk as an SSTable. SSTable - sorted string table, key/value storage sorted by keys. SSTable is on-disk data structure and is always immutable.
F23:SSTableLoader:When a Memtable is full, Cassandra writes to disk as an SSTable. SSTable - sorted string table, key/value storage sorted by keys. SSTable is on-disk data structure and is always immutable.
F23:SSTableMetadata:When a Memtable is full, Cassandra writes to disk as an SSTable. SSTable - sorted string table, key/value storage sorted by keys. SSTable is on-disk data structure and is always immutable.
F23:SSTableReader:When a Memtable is full, Cassandra writes to disk as an SSTable. SSTable - sorted string table, key/value storage sorted by keys. SSTable is on-disk data structure and is always immutable.
F23:SSTableScanner:When a Memtable is full, Cassandra writes to disk as an SSTable. SSTable - sorted string table, key/value storage sorted by keys. SSTable is on-disk data structure and is always immutable.
F23:SSTableSimpleUnsortedWriter:When a Memtable is full, Cassandra writes to disk as an SSTable. SSTable - sorted string table, key/value storage sorted by keys. SSTable is on-disk data structure and is always immutable.
F23:SSTableSimpleWriter:When a Memtable is full, Cassandra writes to disk as an SSTable. SSTable - sorted string table, key/value storage sorted by keys. SSTable is on-disk data structure and is always immutable.
F23:SSTableWriter:When a Memtable is full, Cassandra writes to disk as an SSTable. SSTable - sorted string table, key/value storage sorted by keys. SSTable is on-disk data structure and is always immutable.
F36:AbstractEndpointSnitch:A snitch maps IPs to racks and data centers. It defines how the nodes are grouped together within the overall network topology.  A snitch determines which data centers and racks nodes belong to. Snitches inform Cassandra about the network topology so that requests are routed efficiently and allows Cassandra to distribute replicas by grouping machines into data centers and racks.
F36:AbstractNetworkTopologySnitch:A snitch maps IPs to racks and data centers. It defines how the nodes are grouped together within the overall network topology.  A snitch determines which data centers and racks nodes belong to. Snitches inform Cassandra about the network topology so that requests are routed efficiently and allows Cassandra to distribute replicas by grouping machines into data centers and racks.
F36:AbstractReplicationStrategy:A snitch maps IPs to racks and data centers. It defines how the nodes are grouped together within the overall network topology.  A snitch determines which data centers and racks nodes belong to. Snitches inform Cassandra about the network topology so that requests are routed efficiently and allows Cassandra to distribute replicas by grouping machines into data centers and racks.
F37:DynamicEndpointSnitch:By default, all snitches also use a dynamic snitch layer that monitors read latency and, when possible, routes requests away from poorly-performing nodes. The dynamic snitch is enabled by default and is recommended for use in most deployments.
F37:DynamicEndpointSnitchMBean:By default, all snitches also use a dynamic snitch layer that monitors read latency and, when possible, routes requests away from poorly-performing nodes. The dynamic snitch is enabled by default and is recommended for use in most deployments.
F42:Ec2MultiRegionSnitch:Use the EC2MultiRegionSnitch for deployments on Amazon EC2 where the cluster spans multiple regions. As with the Ec2Snitch, regions are treated as data centers and availability zones are treated as racks within a data center. 
F41:Ec2Snitch:Use the Ec2Snitch for simple cluster deployments on Amazon EC2 where all nodes in the cluster are within a single region. The region is treated as the data center and the availability zones are treated as racks within the data center. 
F36:EndpointSnitchInfo:A snitch maps IPs to racks and data centers. It defines how the nodes are grouped together within the overall network topology.  A snitch determines which data centers and racks nodes belong to. Snitches inform Cassandra about the network topology so that requests are routed efficiently and allows Cassandra to distribute replicas by grouping machines into data centers and racks.
F36:EndpointSnitchInfoMBean:A snitch maps IPs to racks and data centers. It defines how the nodes are grouped together within the overall network topology.  A snitch determines which data centers and racks nodes belong to. Snitches inform Cassandra about the network topology so that requests are routed efficiently and allows Cassandra to distribute replicas by grouping machines into data centers and racks.
F36:IEndpointSnitch:A snitch maps IPs to racks and data centers. It defines how the nodes are grouped together within the overall network topology.  A snitch determines which data centers and racks nodes belong to. Snitches inform Cassandra about the network topology so that requests are routed efficiently and allows Cassandra to distribute replicas by grouping machines into data centers and racks.
F36:ILatencySubscriber:A snitch maps IPs to racks and data centers. It defines how the nodes are grouped together within the overall network topology.  A snitch determines which data centers and racks nodes belong to. Snitches inform Cassandra about the network topology so that requests are routed efficiently and allows Cassandra to distribute replicas by grouping machines into data centers and racks.
F36:LocalStrategy:A snitch maps IPs to racks and data centers. It defines how the nodes are grouped together within the overall network topology.  A snitch determines which data centers and racks nodes belong to. Snitches inform Cassandra about the network topology so that requests are routed efficiently and allows Cassandra to distribute replicas by grouping machines into data centers and racks.
F36:NetworkTopologyStrategy:A snitch maps IPs to racks and data centers. It defines how the nodes are grouped together within the overall network topology.  A snitch determines which data centers and racks nodes belong to. Snitches inform Cassandra about the network topology so that requests are routed efficiently and allows Cassandra to distribute replicas by grouping machines into data centers and racks.
F36:OldNetworkTopologyStrategy:A snitch maps IPs to racks and data centers. It defines how the nodes are grouped together within the overall network topology.  A snitch determines which data centers and racks nodes belong to. Snitches inform Cassandra about the network topology so that requests are routed efficiently and allows Cassandra to distribute replicas by grouping machines into data centers and racks.
F40:PropertyFileSnitch:This snitch uses a user-defined description of the network details located in the cassandra-topology.properties file. Use this snitch when your node IPs are not uniform or if you have complex replication grouping requirements. When using this snitch, you can define your data center names to be whatever you want. 
F39:RackInferringSnitch:The RackInferringSnitch determines the location of nodes by rack and data center, which are assumed to correspond to the 3rd and 2nd octet of the node's IP address, respectively. Use this snitch as an example of writing a custom Snitch class.
F38:SeedProvider:The SimpleSnitch (the default) does not recognize data center or rack information. Use it for single-data center deployments (or single-zone in public clouds).
F38:SimpleSeedProvider:The SimpleSnitch (the default) does not recognize data center or rack information. Use it for single-data center deployments (or single-zone in public clouds).
F38:SimpleSnitch:The SimpleSnitch (the default) does not recognize data center or rack information. Use it for single-data center deployments (or single-zone in public clouds).
F38:SimpleStrategy:The SimpleSnitch (the default) does not recognize data center or rack information. Use it for single-data center deployments (or single-zone in public clouds).
F36:TokenMetadata:A snitch maps IPs to racks and data centers. It defines how the nodes are grouped together within the overall network topology.  A snitch determines which data centers and racks nodes belong to. Snitches inform Cassandra about the network topology so that requests are routed efficiently and allows Cassandra to distribute replicas by grouping machines into data centers and racks.
F43:IAsyncCallback:A new connection between nodes will either stream or message, determining the connection type.
F43:IAsyncResult:A new connection between nodes will either stream or message, determining the connection type.
F43:IMessageCallback:A new connection between nodes will either stream or message, determining the connection type.
F44:IncomingTcpConnection:All ports in cassandra are TCP.
F43:IVerbHandler:A new connection between nodes will either stream or message, determining the connection type.
F43:Message:A new connection between nodes will either stream or message, determining the connection type.
F43:MessageDeliveryTask:A new connection between nodes will either stream or message, determining the connection type.
F43:MessageProducer:A new connection between nodes will either stream or message, determining the connection type.
F43:MessagingService:A new connection between nodes will either stream or message, determining the connection type.
F43:MessagingServiceMBean:A new connection between nodes will either stream or message, determining the connection type.
F44:OutboundTcpConnection:All ports in cassandra are TCP.
F44:OutboundTcpConnectionPool:All ports in cassandra are TCP.
F43:ProtocolHeader:A new connection between nodes will either stream or message, determining the connection type.
F43:ResponseVerbHandler:A new connection between nodes will either stream or message, determining the connection type.
F45:IRequestScheduler:Cassandra uses one thread-per-client for remote procedure calls. For a large number of client connections, this can cause excessive memory usage for the thread stack. cassandra defines a scheduler to handle incoming client requests according to a defined policy. This scheduler only applies to client requests, not inter-node communication.
F45:NoScheduler:Cassandra uses one thread-per-client for remote procedure calls. For a large number of client connections, this can cause excessive memory usage for the thread stack. cassandra defines a scheduler to handle incoming client requests according to a defined policy. This scheduler only applies to client requests, not inter-node communication.
F45:RoundRobinScheduler:Cassandra uses one thread-per-client for remote procedure calls. For a large number of client connections, this can cause excessive memory usage for the thread stack. cassandra defines a scheduler to handle incoming client requests according to a defined policy. This scheduler only applies to client requests, not inter-node communication.
F45:WeightedQueue:Cassandra uses one thread-per-client for remote procedure calls. For a large number of client connections, this can cause excessive memory usage for the thread stack. cassandra defines a scheduler to handle incoming client requests according to a defined policy. This scheduler only applies to client requests, not inter-node communication.
F45:WeightedQueueMBean:Cassandra uses one thread-per-client for remote procedure calls. For a large number of client connections, this can cause excessive memory usage for the thread stack. cassandra defines a scheduler to handle incoming client requests according to a defined policy. This scheduler only applies to client requests, not inter-node communication.
F46:SSLFactory:Cassandra has A Factory for providing and setting up Client and Server SSL wrapped Socket and ServerSocket.
F47:CustomTHsHaServer:In cassandrathe Thrift interface is a legacy API for older clients. Thrift is an interface definition language and binary communication protocol that is used to define and create services for numerous languages. It is used as a remote procedure call (RPC) framework. 
F47:CustomTNonBlockingServer:In cassandrathe Thrift interface is a legacy API for older clients. Thrift is an interface definition language and binary communication protocol that is used to define and create services for numerous languages. It is used as a remote procedure call (RPC) framework. 
F47:CustomTThreadPoolServer:In cassandrathe Thrift interface is a legacy API for older clients. Thrift is an interface definition language and binary communication protocol that is used to define and create services for numerous languages. It is used as a remote procedure call (RPC) framework. 
F47:TBinaryProtocol:In cassandrathe Thrift interface is a legacy API for older clients. Thrift is an interface definition language and binary communication protocol that is used to define and create services for numerous languages. It is used as a remote procedure call (RPC) framework. 
F47:TCustomNonblockingServerSocket:In cassandrathe Thrift interface is a legacy API for older clients. Thrift is an interface definition language and binary communication protocol that is used to define and create services for numerous languages. It is used as a remote procedure call (RPC) framework. 
F47:TCustomServerSocket:In cassandrathe Thrift interface is a legacy API for older clients. Thrift is an interface definition language and binary communication protocol that is used to define and create services for numerous languages. It is used as a remote procedure call (RPC) framework. 
F47:ThriftValidation:In cassandrathe Thrift interface is a legacy API for older clients. Thrift is an interface definition language and binary communication protocol that is used to define and create services for numerous languages. It is used as a remote procedure call (RPC) framework. 
F48:FileStreamTask:Streaming is a component which handles data (part of SSTable file) exchange among nodes in the cluster. When you bootstrap a new node, it gets data from existing nodes using streaming.
F48:IncomingStreamReader:Streaming is a component which handles data (part of SSTable file) exchange among nodes in the cluster. When you bootstrap a new node, it gets data from existing nodes using streaming.
F48:StreamHeader:Streaming is a component which handles data (part of SSTable file) exchange among nodes in the cluster. When you bootstrap a new node, it gets data from existing nodes using streaming.
F48:StreamIn:Streaming is a component which handles data (part of SSTable file) exchange among nodes in the cluster. When you bootstrap a new node, it gets data from existing nodes using streaming.
F48:StreamingRepairTask:Streaming is a component which handles data (part of SSTable file) exchange among nodes in the cluster. When you bootstrap a new node, it gets data from existing nodes using streaming.
F48:StreamingService:Streaming is a component which handles data (part of SSTable file) exchange among nodes in the cluster. When you bootstrap a new node, it gets data from existing nodes using streaming.
F48:StreamingServiceMBean:Streaming is a component which handles data (part of SSTable file) exchange among nodes in the cluster. When you bootstrap a new node, it gets data from existing nodes using streaming.
F48:StreamInSession:Streaming is a component which handles data (part of SSTable file) exchange among nodes in the cluster. When you bootstrap a new node, it gets data from existing nodes using streaming.
F48:StreamOut:Streaming is a component which handles data (part of SSTable file) exchange among nodes in the cluster. When you bootstrap a new node, it gets data from existing nodes using streaming.
F48:StreamOutSession:Streaming is a component which handles data (part of SSTable file) exchange among nodes in the cluster. When you bootstrap a new node, it gets data from existing nodes using streaming.
F48:StreamReply:Streaming is a component which handles data (part of SSTable file) exchange among nodes in the cluster. When you bootstrap a new node, it gets data from existing nodes using streaming.
F48:StreamReplyVerbHandler:Streaming is a component which handles data (part of SSTable file) exchange among nodes in the cluster. When you bootstrap a new node, it gets data from existing nodes using streaming.
F48:StreamRequestMessage:Streaming is a component which handles data (part of SSTable file) exchange among nodes in the cluster. When you bootstrap a new node, it gets data from existing nodes using streaming.
F48:StreamRequestVerbHandler:Streaming is a component which handles data (part of SSTable file) exchange among nodes in the cluster. When you bootstrap a new node, it gets data from existing nodes using streaming.
F50:CloseableIterator: